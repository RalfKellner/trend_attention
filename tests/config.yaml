input_dim: 5
input_activation_name: "Identity"
hidden_feature_dim: 10
hidden_activation_function_name: "LeakyReLU"
embedding_dim: 4 
seq_len: 5
num_heads: 2
masked_attention: True
use_bias: False
attention_dropout: 0.25
feature_engineering_dropout: 0.25
n_layers: 2
task: "binary_classification"